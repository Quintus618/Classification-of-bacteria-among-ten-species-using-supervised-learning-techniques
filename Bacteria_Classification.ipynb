{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea2341c",
   "metadata": {},
   "source": [
    "# OUTLINE\n",
    "\n",
    "- ## Libraries import\n",
    "\n",
    "- ## Preprocessing\n",
    "1) remove missing data\n",
    "2) extract X and y\n",
    "3) replace bacteria's names with numbers\n",
    "4) Split training (64%), validation (16%) and test set (20%)  (with the cross validation and the learning curves, there is already the creation of the validation set) \n",
    "5) data normalization using Z-norm \n",
    "\n",
    "- ## Models creation\n",
    "1) Model selection : KNN, Random forest and MLP \n",
    "2) First score estimation for each model \n",
    "\n",
    "- ### KNN\n",
    "0) Explanation of the principle behind this model \n",
    "1) Bias and Variance : impact of each parameter \n",
    "2) Hyper parameter tuning from scratch \n",
    "3) Automatic hyper parameter tuning with GridSearchCV \n",
    "4) Validation curves : analysis underfitting/overfitting \n",
    "\n",
    "- ### Random Forest\n",
    "0) Explanation of the principle behind this model \n",
    "1) Bias and Variance : impact of each parameter \n",
    "2) Validation curves : analysis underfitting/overfitting \n",
    "3) Automatic hyper parameter tuning with GridSearchCV \n",
    "4) Display of decision trees (for interpretability) \n",
    "\n",
    "TO DO : Discussion concerning the method that allows the selection of the feature entropy/gini\n",
    "\n",
    "- ### MLP\n",
    "0) Explanation of the principle behind this model \n",
    "1) Discussion about the architecture \n",
    "2) Bias and Variance : impact of each parameter \n",
    "3) Validation curves : analysis underfitting/overfitting \n",
    "4) Automatic hyper parameter tuning with GridSearchCV \n",
    "\n",
    "- ## Result comparison\n",
    "1) Confusion Matrix \n",
    "2) Precision and Accuracy \n",
    "3) ROC \n",
    "4) Complexity of each model and time computation \n",
    "\n",
    "\n",
    "- ## Interpretability discussion\n",
    "1) Complexity and score tradeoff \n",
    "2) Interpretability of each model \n",
    "3) Conclusion \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d425c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Importation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Models importation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044a8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset\n",
    "data = pd.read_csv ('bacteria.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27666079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>A0T0G0C10</th>\n",
       "      <th>A0T0G1C9</th>\n",
       "      <th>A0T0G2C8</th>\n",
       "      <th>A0T0G3C7</th>\n",
       "      <th>A0T0G4C6</th>\n",
       "      <th>A0T0G5C5</th>\n",
       "      <th>A0T0G6C4</th>\n",
       "      <th>A0T0G7C3</th>\n",
       "      <th>A0T0G8C2</th>\n",
       "      <th>...</th>\n",
       "      <th>A8T0G1C1</th>\n",
       "      <th>A8T0G2C0</th>\n",
       "      <th>A8T1G0C1</th>\n",
       "      <th>A8T1G1C0</th>\n",
       "      <th>A8T2G0C0</th>\n",
       "      <th>A9T0G0C1</th>\n",
       "      <th>A9T0G1C0</th>\n",
       "      <th>A9T1G0C0</th>\n",
       "      <th>A10T0G0C0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.046326e-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.632568e-08</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  \\\n",
       "0       0 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "1       1 -9.536743e-07 -0.000010 -0.000043  0.000886 -0.000200  0.000760   \n",
       "2       2 -9.536743e-07 -0.000002  0.000007  0.000129  0.000268  0.000270   \n",
       "3       3  4.632568e-08 -0.000006  0.000012  0.000245  0.000492  0.000522   \n",
       "4       4 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "\n",
       "   A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G1C1  A8T0G2C0  A8T1G0C1  A8T1G1C0  \\\n",
       "0 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n",
       "1 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043  0.000914  0.000914   \n",
       "2  0.000243  0.000125  0.000001  ...  0.000084  0.000048  0.000081  0.000106   \n",
       "3  0.000396  0.000197 -0.000003  ...  0.000151  0.000100  0.000180  0.000202   \n",
       "4 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n",
       "\n",
       "   A8T2G0C0  A9T0G0C1  A9T0G1C0  A9T1G0C0     A10T0G0C0  target  \n",
       "0 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07       0  \n",
       "1 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07       1  \n",
       "2  0.000072  0.000010  0.000008  0.000019  1.046326e-06       1  \n",
       "3  0.000153  0.000021  0.000015  0.000046 -9.536743e-07       1  \n",
       "4 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07       2  \n",
       "\n",
       "[5 rows x 288 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete all incomplete data\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "# replacement of all bacteria names with numbers\n",
    "data['target'].replace(['Streptococcus_pyogenes',\n",
    "                        'Salmonella_enterica',\n",
    "                        'Enterococcus_hirae',\n",
    "                        'Streptococcus_pneumoniae',\n",
    "                        'Staphylococcus_aureus',\n",
    "                        'Klebsiella_pneumoniae',\n",
    "                        'Bacteroides_fragilis',\n",
    "                        'Escherichia_coli',\n",
    "                        'Campylobacter_jejuni',\n",
    "                        'Escherichia_fergusonii'],\n",
    "                      [0,1,2,3,4,5,6,7,8,9], inplace=True)\n",
    "\n",
    "# print first data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6f3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first and the last column\n",
    "X = data.drop(['target', 'row_id'], axis=1)\n",
    "\n",
    "# extraction of the last column\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e33a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into two parts: training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split training set into two parts: training set and validation set\n",
    "X_train_splitted, X_val, y_train_splitted, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale X_train, X_val, X_test using Z-score normalization\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_train_splitted_scaled = sc.fit_transform(X_train_splitted)\n",
    "X_val_scaled = sc.fit_transform(X_val)\n",
    "X_test_scaled = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3787a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the models to be tested\n",
    "models_list = []\n",
    "models_list.append(KNeighborsClassifier(n_neighbors=1, weights='uniform', p=2))\n",
    "models_list.append(DecisionTreeClassifier())\n",
    "models_list.append(RandomForestClassifier())\n",
    "models_list.append(MLPClassifier(random_state=42, max_iter=2000, hidden_layer_sizes=(100,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84454812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "score_list_train = []\n",
    "score_list_val = []\n",
    "execution_time = []\n",
    "models_tested = ['KNN', \n",
    "                 'Decision Tree', \n",
    "                 'Random Forest',\n",
    "                 'MLP'\n",
    "                 ]\n",
    "\n",
    "for model in models_list:\n",
    "\n",
    "    # start computing time\n",
    "    st = time.time()\n",
    "\n",
    "    # training\n",
    "    model.fit(X_train_splitted_scaled, y_train_splitted) \n",
    "    et = time.time()\n",
    "\n",
    "    # compute the execution time\n",
    "    elapsed_time = et - st\n",
    "\n",
    "    score_list_train.append(model.score(X_train_splitted_scaled, y_train_splitted))\n",
    "    score_list_val.append(model.score(X_val_scaled, y_val))\n",
    "    execution_time.append(elapsed_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66afd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train score</th>\n",
       "      <th>Test score</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987156</td>\n",
       "      <td>0.335388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951313</td>\n",
       "      <td>20.567937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990469</td>\n",
       "      <td>74.719966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.997461</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>129.116718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train score  Test score  Execution Time\n",
       "0            KNN     1.000000    0.987156        0.335388\n",
       "1  Decision Tree     1.000000    0.951313       20.567937\n",
       "2  Random Forest     1.000000    0.990469       74.719966\n",
       "3            MLP     0.997461    0.984500      129.116718"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model':models_tested, 'Train score':score_list_train, \n",
    "                       'Test score':score_list_val, 'Execution Time':execution_time})\n",
    "\n",
    "# print the result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fe446",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "0) Explanation of the principle behind this model \n",
    "\n",
    "The KNN describes the K nearest neighbors algorithm and is a supervised machine learning classification algorithm.\n",
    "To classify new data, its distance to the features of the classified data is computed and it is put in the predominant class in the K nearest neighbors.\n",
    "Depending on the type of weighting, the predominant class can be the class that accumulates the most neighbors or the class with the most and closest neighbors.\n",
    "\n",
    "<img src=\"images/knn.png\" alt=\"KNN algorithm explanation\" width=\"800\"/>\\\n",
    "*https://www.ibm.com/it-it/topics/knn*\n",
    "\n",
    "We use 2 ways to evaluate the distance :\n",
    "- Manhattan distance or *L1* : $\\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n",
    "- Euclidian distance or *L2* : $\\sum_{i=1}^{n} |x_i - y_i|$\n",
    "\n",
    "In this type of model, the most impacting parameter is K: the number of neighbors to consider.\n",
    "\n",
    "1) Bias and Variance : impact of each parameter \n",
    "\n",
    "The K number of neighbors greatly impacts both Bias and Variance. When K has a small value, the Variance is high and when K has a large value the Bias is high.\n",
    "Thus, both Bias and Variance cannot be low and the the value of K must be selected to find a good compromise between the Bias and the Variance.\n",
    "\n",
    "2) Hyper parameter tuning from scratch\n",
    "3) Automatic hyper parameter tuning with GridSearchCV \n",
    "4) Learning curves : analysis underfitting/overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model  Train score  Test score  Execution Time  n_neighbors   weights  p\n",
      "0    KKN     1.000000    1.000000        0.279999            1   uniform  1\n",
      "1    KKN     1.000000    1.000000        0.258999            1   uniform  2\n",
      "2    KKN     1.000000    1.000000        0.247001            1  distance  1\n",
      "3    KKN     1.000000    1.000000        0.318001            1  distance  2\n",
      "4    KKN     0.993225    0.993812        0.248001            3   uniform  1\n",
      "5    KKN     0.992200    0.992656        0.260000            3   uniform  2\n",
      "6    KKN     1.000000    1.000000        0.249000            3  distance  1\n",
      "7    KKN     1.000000    0.999812        0.258001            3  distance  2\n",
      "8    KKN     0.981925    0.983000        0.248003            5   uniform  1\n",
      "9    KKN     0.979094    0.980219        0.253000            5   uniform  2\n",
      "10   KKN     1.000000    1.000000        0.251000            5  distance  1\n",
      "11   KKN     1.000000    0.999781        0.250001            5  distance  2\n",
      "12   KKN     0.971419    0.971812        0.254000            7   uniform  1\n",
      "13   KKN     0.967688    0.968875        0.251003            7   uniform  2\n",
      "14   KKN     1.000000    1.000000        0.245999            7  distance  1\n",
      "15   KKN     1.000000    0.999656        0.260000            7  distance  2\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [1,3,5,7] # number k of neighbors \n",
    "weights = ['uniform', 'distance'] # weight function used in prediction\n",
    "p = [1,2] \n",
    "\n",
    "score_list_train_all = []\n",
    "score_list_val_all = []\n",
    "execution_time_all = []\n",
    "n_neighbors_all = []\n",
    "weights_all = []\n",
    "p_all = []\n",
    "\n",
    "# Hyperparameter tuning for KNN from scratch\n",
    "for n in n_neighbors:\n",
    "    for w in weights:\n",
    "        for pp in p:\n",
    "            st = time.time()\n",
    "            model = KNeighborsClassifier(n_neighbors=n, weights=w, p=pp)\n",
    "            model.fit(X_train_splitted_scaled, y_train)\n",
    "            et = time.time()\n",
    "            elapsed_time = et - st\n",
    "            score_list_train_all.append(model.score(X_train_splitted_scaled, y_train))\n",
    "            score_list_val_all.append(model.score(X_val_scaled, y_val))\n",
    "            execution_time_all.append(elapsed_time)\n",
    "            n_neighbors_all.append(n)\n",
    "            weights_all.append(w)\n",
    "            p_all.append(pp)\n",
    "            result_all = pd.DataFrame({'Model':'KKN', 'Train score':score_list_train_all,\n",
    "                                   'Test score':score_list_val_all, 'Execution Time':execution_time_all, 'n_neighbors':n_neighbors_all, 'weights':weights_all, 'p': p_all})\n",
    "print(result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.988025\n",
      "Param: {'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Automatic hyperparameter tuning for KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_KNN = {'n_neighbors' : [1,3,5,7],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2] # p=1 : manhattan_distance, p=2 : euclidean_distance\n",
    "              }\n",
    "\n",
    "grid_KNN = GridSearchCV(KNeighborsClassifier(), param_grid_KNN, cv=5) # 5-fold cross validation\n",
    "grid_KNN.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best score:\", grid_KNN.best_score_)\n",
    "print(\"Param:\", grid_KNN.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8005cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1, p=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1, p=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1, p=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model for KNN\n",
    "best_KNN_model = KNeighborsClassifier(n_neighbors=grid_KNN.best_params_['n_neighbors'], weights=grid_KNN.best_params_['weights'], p=grid_KNN.best_params_['p'])\n",
    "best_KNN_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "534e795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation curve for KNN on n_neighbors: number K of neighbors \n",
    "\n",
    "param_K_range = [1,3,5,7,9,11]\n",
    "train_scores_KNN, test_scores_KNN = validation_curve(KNeighborsClassifier(), X_train_scaled, y_train, param_name=\"n_neighbors\", param_range=param_K_range, cv=5) # 5-fold cross validation\n",
    "\n",
    "train_scores_mean_KNN = np.mean(train_scores_KNN, axis=1) # mean of the training scores\n",
    "train_scores_std_KNN = np.std(train_scores_KNN, axis=1) # standard deviation of the training scores\n",
    "test_scores_mean_KNN = np.mean(test_scores_KNN, axis=1) # mean of the test scores\n",
    "test_scores_std_KNN = np.std(test_scores_KNN, axis=1) # standard deviation of the test scores\n",
    "\n",
    "plt.plot(param_K_range, train_scores_mean_KNN,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(param_K_range, test_scores_mean_KNN,\n",
    "   label = \"Testing Score\", color = 'g')\n",
    "\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf88564",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "0) Explanation of the principle behind this model \n",
    "1) Bias and Variance : impact of each parameter \n",
    "2) Validation curves : analysis underfitting/overfitting \n",
    "3) Automatic hyper parameter tuning with GridSearchCV \n",
    "4) Display of decision trees (for interpretability) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace22ea0",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for Random Forest on n_estimators: number of trees in the forest\n",
    "param_n_estimators_range = [10, 50, 100, 200, 300, 400, 500, 600]\n",
    "train_scores_RF, test_scores_RF = validation_curve(RandomForestClassifier(), X_train_scaled, y_train, param_name=\"n_estimators\", param_range=param_n_estimators_range, cv=5) # 5-fold cross validation\n",
    "\n",
    "train_scores_mean_RF = np.mean(train_scores_RF, axis=1) # mean of the training scores\n",
    "train_scores_std_RF = np.std(train_scores_RF, axis=1) # standard deviation of the training scores\n",
    "test_scores_mean_RF = np.mean(test_scores_RF, axis=1) # mean of the test scores\n",
    "test_scores_std_RF = np.std(test_scores_RF, axis=1) # standard deviation of the test scores\n",
    "\n",
    "plt.plot(param_n_estimators_range, train_scores_mean_RF,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(param_n_estimators_range, test_scores_mean_RF,\n",
    "   label = \"Testing Score\", color = 'g')\n",
    "\n",
    "plt.title(\"Validation Curve with Random Forest on the number of trees\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for Random Forest on max_depth: maximum depth of the tree\n",
    "param_max_depth_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 50, 90, 130, 170, 210, 250]\n",
    "train_scores_RF2, test_scores_RF2 = validation_curve(RandomForestClassifier(), X_train_scaled, y_train, param_name=\"max_depth\", param_range=param_max_depth_range, cv=5) # 5-fold cross validation\n",
    "\n",
    "train_scores_mean_RF2 = np.mean(train_scores_RF2, axis=1) # mean of the training scores\n",
    "train_scores_std_RF2 = np.std(train_scores_RF2, axis=1) # standard deviation of the training scores\n",
    "test_scores_mean_RF2 = np.mean(test_scores_RF2, axis=1) # mean of the test scores\n",
    "test_scores_std_RF2 = np.std(test_scores_RF2, axis=1) # standard deviation of the test scores\n",
    "\n",
    "plt.plot(param_max_depth_range, train_scores_mean_RF2,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(param_max_depth_range, test_scores_mean_RF2,\n",
    "   label = \"Testing Score\", color = 'g')\n",
    "\n",
    "plt.title(\"Validation Curve with Random Forest on the maximum depth of each tree\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic hyperparameter tuning for Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_random_forest = {'n_estimators' : [100, 200, 300],\n",
    "              'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth' : [10, 50, 100, 200, 250, 280]\n",
    "              }\n",
    "\n",
    "grid_random_forest = GridSearchCV(RandomForestClassifier(), param_grid_random_forest, cv=5) # 5-fold cross validation\n",
    "grid_random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best score:\", grid_random_forest.best_score_)\n",
    "print(\"Param:\", grid_random_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best random forest model\n",
    "best_random_forest = grid_random_forest.best_params_\n",
    "best_random_forest_model = RandomForestClassifier(n_estimators=best_random_forest['n_estimators'], criterion=best_random_forest['criterion'], max_depth=best_random_forest['max_depth'])\n",
    "best_random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the three first trees of the random forest\n",
    "from sklearn import tree\n",
    "tree.plot_tree(best_random_forest_model.estimators_[0], filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01077484",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "0) Explanation of the principle behind this model \n",
    "1) Discussion about the architecture \n",
    "2) Bias and Variance : impact of each parameter \n",
    "3) Validation curves : analysis underfitting/overfitting \n",
    "4) Automatic hyper parameter tuning with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f700b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_neural_network = {\n",
    "    'hidden_layer_sizes': [(10, 10, 10), (50, 30, 10), (60, 40, 20), (100, 60, 20)],\n",
    "    'activation': ['tahn', 'relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'max_iter': [200, 1000, 2000],\n",
    "    'early_stopping': [True],\n",
    "    'n_iter_no_change': [5, 10, 15],\n",
    "    'shuffle': [True],\n",
    "    'alpha': [1e-4, 2e-4, 5e-4],\n",
    "    'learning_rate_init': [1e-3, 2e-3, 5e-3]\n",
    "}\n",
    "\n",
    "grid_neural_network = GridSearchCV(MLPClassifier(), param_grid_neural_network, cv=5)\n",
    "grid_neural_network.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best score:\", grid_neural_network.best_score_)\n",
    "print(\"Param:\", grid_neural_network.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best neural network model\n",
    "best_neural_network_params = grid_neural_network.best_params_\n",
    "best_neural_network_model = MLPClassifier(\n",
    "    hidden_layer_sizes=best_neural_network_params['hidden_layer_sizes'],\n",
    "    activation=best_neural_network_params['activation'],\n",
    "    solver=best_neural_network_params['solver'],\n",
    "    max_iter=best_neural_network_params['max_iter'],\n",
    "    early_stopping=best_neural_network_params['early_stopping'],\n",
    "    n_iter_no_change=best_neural_network_params['n_iter_no_change'],\n",
    "    shuffle=best_neural_network_params['shuffle'],\n",
    "    alpha=best_neural_network_params['alpha'],\n",
    "    learning_rate_init=best_neural_network_params['learning_rate_init']\n",
    ")\n",
    "best_neural_network_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd939bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for neural network on number of hidden layers \n",
    "\n",
    "param_n_layers = [(10), (10, 10), (10, 10, 10), (10, 10, 10, 10, 10)]\n",
    "train_scores_KNN, test_scores_KNN = validation_curve(MLPClassifier(), X_train_scaled, y_train, param_name=\"hidden_layers\", param_range=param_n_layers, cv=5) # 5-fold cross validation\n",
    "\n",
    "train_scores_mean_KNN = np.mean(train_scores_KNN, axis=1) # mean of the training scores\n",
    "train_scores_std_KNN = np.std(train_scores_KNN, axis=1) # standard deviation of the training scores\n",
    "test_scores_mean_KNN = np.mean(test_scores_KNN, axis=1) # mean of the test scores\n",
    "test_scores_std_KNN = np.std(test_scores_KNN, axis=1) # standard deviation of the test scores\n",
    "\n",
    "plt.plot(param_K_range, train_scores_mean_KNN,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(param_K_range, test_scores_mean_KNN,\n",
    "   label = \"Testing Score\", color = 'g')\n",
    "\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for neural network on size of hidden layers \n",
    "\n",
    "param_layers_sizes = [(10), (30), (50), (70), (90)]\n",
    "train_scores_KNN, test_scores_KNN = validation_curve(MLPClassifier(), X_train_scaled, y_train, param_name=\"hidden_layers\", param_range=param_layers_sizes, cv=5) # 5-fold cross validation\n",
    "\n",
    "train_scores_mean_KNN = np.mean(train_scores_KNN, axis=1) # mean of the training scores\n",
    "train_scores_std_KNN = np.std(train_scores_KNN, axis=1) # standard deviation of the training scores\n",
    "test_scores_mean_KNN = np.mean(test_scores_KNN, axis=1) # mean of the test scores\n",
    "test_scores_std_KNN = np.std(test_scores_KNN, axis=1) # standard deviation of the test scores\n",
    "\n",
    "plt.plot(param_K_range, train_scores_mean_KNN,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(param_K_range, test_scores_mean_KNN,\n",
    "   label = \"Testing Score\", color = 'g')\n",
    "\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682dde6",
   "metadata": {},
   "source": [
    "# Result comparison\n",
    "1) Confusion Matrix \n",
    "2) Precision and Accuracy \n",
    "3) ROC \n",
    "4) Complexity of each model and time computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the three confusion matrices on the same plot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_KNN = best_KNN_model.predict(X_test_scaled)\n",
    "y_pred_RF = best_random_forest_model.predict(X_test_scaled)\n",
    "y_pred_NN = best_neural_network_model.predict(X_test_scaled)\n",
    "\n",
    "confusion_matrix_KNN = confusion_matrix(y_test, y_pred_KNN)\n",
    "confusion_matrix_RF = confusion_matrix(y_test, y_pred_RF)\n",
    "confusion_matrix_NN = confusion_matrix(y_test, y_pred_NN)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].matshow(confusion_matrix_KNN, cmap=plt.cm.Blues, alpha=0.3)\n",
    "ax[0].set_title(\"Confusion matrix for KNN\")\n",
    "ax[1].matshow(confusion_matrix_RF, cmap=plt.cm.Blues, alpha=0.3)\n",
    "ax[1].set_title(\"Confusion matrix for Random Forest\")\n",
    "ax[2].matshow(confusion_matrix_NN, cmap=plt.cm.Blues, alpha=0.3)\n",
    "ax[2].set_title(\"Confusion matrix for Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and accuracy for KNN\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "\n",
    "precision_KNN = precision_score(y_test, y_pred_KNN, average='weighted')\n",
    "accuracy_KNN = accuracy_score(y_test, y_pred_KNN)\n",
    "\n",
    "print(\"Precision for KNN:\", precision_KNN)\n",
    "print(\"Accuracy for KNN:\", accuracy_KNN)\n",
    "\n",
    "# Precision and accuracy for Random Forest\n",
    "\n",
    "precision_RF = precision_score(y_test, y_pred_RF, average='weighted')\n",
    "accuracy_RF = accuracy_score(y_test, y_pred_RF)\n",
    "\n",
    "print(\"Precision for Random Forest:\", precision_RF)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_RF)\n",
    "\n",
    "# Precision and accuracy for Neural Network\n",
    "\n",
    "precision_NN = precision_score(y_test, y_pred_NN, average='weighted')\n",
    "accuracy_NN = accuracy_score(y_test, y_pred_NN)\n",
    "\n",
    "print(\"Precision for Neural Network:\", precision_NN)\n",
    "print(\"Accuracy for Neural Network:\", accuracy_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for KNN\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_test, y_pred_KNN)\n",
    "roc_auc_KNN = auc(fpr_KNN, tpr_KNN)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_KNN, tpr_KNN, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_KNN)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for KNN')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# ROC curve for Random Forest\n",
    "\n",
    "fpr_RF, tpr_RF, thresholds_RF = roc_curve(y_test, y_pred_RF)\n",
    "roc_auc_RF = auc(fpr_RF, tpr_RF)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_RF, tpr_RF, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_RF)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Random Forest')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# ROC curve for Neural Network\n",
    "\n",
    "fpr_NN, tpr_NN, thresholds_NN = roc_curve(y_test, y_pred_NN)\n",
    "roc_auc_NN = auc(fpr_NN, tpr_NN)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_NN, tpr_NN, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_NN)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Neural Network')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27f6dc",
   "metadata": {},
   "source": [
    "# Interpretability Discussion\n",
    "1) Complexity and score tradeoff \n",
    "2) Interpretability of each model \n",
    "3) Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9a667b43f80089283f9f7f5a6ffa5871ef456eb03c55aac216a9928a18eb654"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
